% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cv.trendfilter.R
\name{cv.trendfilter}
\alias{cv.trendfilter}
\title{Optimize the trend filtering hyperparameter (by V-fold cross validation)}
\usage{
cv.trendfilter(
  x,
  y,
  weights = NULL,
  k = 2L,
  nlambda = 250L,
  lambda = NULL,
  V = 10L,
  validation.error.type = c("WMAE", "WMSE", "MAE", "MSE"),
  n.eval = 1500L,
  x.eval = NULL,
  thinning = NULL,
  max_iter = 600L,
  obj_tol = 1e-10,
  mc.cores = max(c(parallel::detectCores() - 2), 1)
)
}
\arguments{
\item{x}{The vector of the observed inputs.}

\item{y}{The vector of the observed outputs.}

\item{weights}{A vector of weights for the observed outputs. These are defined as 
\code{weights = 1 / sigma^2}, where \code{sigma} is a vector of standard 
errors of the uncertainty in the output measurements. \code{weights} should 
either have length equal to 1 (corresponding to observations with a constant 
(scalar) variance of \code{sigma = 1/sqrt(weights)}) or length equal to 
\code{length(y)} (i.e. heteroskedastic outputs).}

\item{k}{The degree of the trend filtering estimator. Defaults to 
\code{k=2} (quadratic trend filtering). Must be one of \code{k = 0,1,2,3},
although \code{k=3} is discouraged due to algorithmic instability (and is
visually indistinguishable from \code{k=2} anyway).}

\item{nlambda}{The number of trend filtering hyperparameter values 
to run the grid search over. If \code{lambda = NULL}, a grid of length 
\code{nlambda} is constructed internally.}

\item{lambda}{Overrides \code{nlambda} if passed. A user-supplied vector of 
trend filtering hyperparameter values to run the grid search over. Usually, 
let them be equally-spaced in log-space (see Examples), and good to 
provide them in descending order. Do not use this argument unless you know
what you are doing.}

\item{V}{The number of folds the data are split into for the V-fold cross
validation. Defaults to \code{V=10} (recommended).
\code{V=length(x)} is equivalent to leave-one-out cross validation.}

\item{validation.error.type}{Type of error to optimize during cross
validation. One of \code{c("WMAE","WMSE","MAE","MSE")}, i.e. mean-absolute 
deviations error, mean-squared error, and their weighted counterparts. That 
is, \cr \cr 
\mjeqn{\text{WMAE}(\lambda) = \frac{1}{n}\sum_{i=1}^{n} |y_i - \widehat{f}(x_i; \lambda)|\frac{\sqrt{w_i}}{\sum_j\sqrt{w_j}}}{ascii} \cr 
\mjeqn{\text{WMSE}(\lambda) = \frac{1}{n}\sum_{i=1}^{n} |y_i - \widehat{f}(x_i; \lambda)|^2\frac{w_i}{\sum_jw_j}}{ascii} \cr 
\mjeqn{\text{MAE}(\lambda) = \frac{1}{n}\sum_{i=1}^{n} |y_i - \widehat{f}(x_i; \lambda)|}{ascii} \cr 
\mjeqn{\text{MSE}(\lambda) = \frac{1}{n}\sum_{i=1}^{n} |y_i - \widehat{f}(x_i; \lambda)|^2}{ascii} \cr \cr 
where \mjeqn{\widehat{f}(x_i; \lambda)}{ascii} is the trend filtering 
estimate with hyperparameter \eqn{\lambda}, evaluated at 
\mjeqn{x_i}{ascii}. If \code{weights = NULL}, then the weighted and 
unweighted counterparts are equivalent. In short, weighting helps combat
heteroskedasticity and absolute error decreases sensitivity to outliers.
Defaults to \code{"WMAE"}.}

\item{n.eval}{The length of the equally-spaced input grid to evaluate the 
optimized trend filtering estimate on.}

\item{x.eval}{Overrides \code{n.eval} if passed. A user-supplied grid of 
inputs to evaluate the optimized trend filtering estimate on.}

\item{thinning}{If \code{TRUE}, then the data are preprocessed so 
that a smaller, better conditioned data set is used for fitting. When set to
\code{NULL}, the default, function will auto detect whether thinning should 
be applied (i.e., cases in which the numerical fitting algorithm will 
struggle to converge).}

\item{max_iter}{Maximum iterations allowed for the trend filtering 
convex optimization 
[\href{http://www.stat.cmu.edu/~ryantibs/papers/fasttf.pdf}{Ramdas & Tibshirani (2015)}]. 
Defaults to \code{max_iter = 600L}. Increase this if the trend 
filtering estimate does not appear to have fully converged to a reasonable 
estimate of the signal.}

\item{obj_tol}{The tolerance used in the convex optimization stopping 
criterion; when the relative change in the objective function is less than 
this value, the algorithm terminates. Decrease this if the trend 
filtering estimate does not appear to have fully converged to a reasonable 
estimate of the signal.}

\item{mc.cores}{Multi-core computing (for speedups): The number of cores to
utilize. If 4 or more cores are detected, then the default is to utilize
\code{min(V, detected.cores - 2)}. Else, \code{mc.cores = 1}.}
}
\value{
An object of class 'cv.trendfilter'. This is a list with the 
following elements:
\item{x.eval}{The grid of inputs the optimized trend filtering estimate was 
evaluated on.}
\item{tf.estimate}{The optimized trend filtering estimate of the signal, 
evaluated on \code{x.eval}.}
\item{validation.method}{"cv"}
\item{V}{The number of folds the data are split into for the V-fold cross
validation.}
\item{validation.error.type}{Type of error that validation was performed on. 
One of \code{c("WMAE","WMSE","MAE","MSE")}.}
\item{lambda}{Vector of hyperparameter values tested during validation. This
vector will always be returned in descending order, regardless of the 
ordering provided by the user. The indices \code{i.min} and \code{i.1se}
correspond to this descending ordering.}
\item{error}{Vector of cross validation errors for the given hyperparameter 
values.}
\item{se.error}{The standard errors of the cross validation errors.
These are particularly useful for implementing the ``1-standard-error rule''. 
The 1-SE rule favors a smoother trend filtering estimate by, instead of 
using the hyperparameter that minimizes the CV error, instead uses the 
largest hyperparameter that has a CV error within 1 standard error of the
smallest CV error.}
\item{lambda.min}{Hyperparameter value that minimizes the SURE error curve.}
\item{lambda.1se}{The largest hyperparameter value that is still within one
standard error of the minimum hyperparameter's cross validation error.}
\item{df}{Vector of effective degrees of freedom for trend filtering
estimators fit during validation.}
\item{df.min}{The effective degrees of freedom of the optimally-tuned trend 
filtering estimator.}
\item{df.1se}{The effective degrees of freedom of the 1-stand-error rule
trend filtering estimator.}
\item{i.min}{The index of \code{lambda} that minimizes the cross validation 
error.}
\item{i.1se}{The index of \code{lambda} that gives the largest hyperparameter
value that has a cross validation error within 1 standard error of the 
minimum of the cross validation error curves.}
\item{x}{The vector of the observed inputs.}
\item{y}{The vector of the observed outputs.}
\item{weights}{A vector of weights for the observed outputs. These are
defined as \code{weights = 1/sigma^2}, where \code{sigma} is a vector of 
standard errors of the uncertainty in the measured outputs.}
\item{fitted.values}{The trend filtering estimate of the signal, evaluated at
the observed inputs \code{x}.}
\item{residuals}{\code{residuals = y - fitted.values}.}
\item{k}{The degree of the trend filtering estimator.}
\item{thinning}{If \code{TRUE}, then the data are preprocessed so 
that a smaller, better conditioned data set is used for fitting. When set to
\code{NULL}, the default, function will auto detect whether thinning should 
be applied (i.e., cases in which the numerical fitting algorithm will 
struggle to converge).}
\item{max_iter}{Maximum iterations allowed for the trend filtering 
convex optimization 
[\href{http://www.stat.cmu.edu/~ryantibs/papers/fasttf.pdf}{Ramdas & Tibshirani (2015)}]. 
Increase this if the trend filtering estimate does not appear to have fully 
converged to a reasonable estimate of the signal.}
\item{obj_tol}{The tolerance used in the convex optimization stopping 
criterion; when the relative change in the objective function is less than 
this value, the algorithm terminates. Decrease this if the trend filtering 
estimate does not appear to have fully converged to a reasonable estimate of 
the signal.}
}
\description{
\loadmathjax{} \code{cv.trendfilter} performs V-fold cross validation to
estimate the random-input squared error of a trend filtering estimator over 
a grid of hyperparameter values and returns the optimized estimator.
}
\examples{
#############################################################################
##                    Quasar Lyman-alpha forest example                    ##
#############################################################################

# Load Lyman-alpha forest spectral observations of an SDSS quasar at redshift 
# z = 2.953. SDSS spectra are equally spaced in log10 wavelength space.

data(quasar_spec)
data(plotting_utilities)


# Run the cross validation for a quadratic trend filtering estimator, i.e. 
# k = 2 (default)

cv.obj <- cv.trendfilter(x = log10.wavelength,
                         y = flux,
                         weights = weights)

                                          
# Extract the CV error curve and optimized trend filtering estimate from 
# the output

log.lambda <- log(cv.obj$lambda)
error <- cv.obj$error
log.lambda.min <- log(cv.obj$lambda.min)

log10.wavelength.eval <- cv.obj$x.eval
tf.estimate <- cv.obj$tf.estimate


# Transform the inputs to wavelength space (in Angstroms)

wavelength <- 10 ^ (log10.wavelength)
wavelength.eval <- 10 ^ (log10.wavelength.eval)


# Plot the results

par(mfrow = c(2,1), mar = c(5,4,2.5,1) + 0.1)
plot(x = log.lambda, y = error, main = "CV error curve", 
     xlab = "log(lambda)", ylab = "CV error")
abline(v = log.lambda.min, lty = 2, col = "blue3")
text(x = log.lambda.min, y = par("usr")[4], 
     labels = "optimal hyperparameter", pos = 1, col = "blue3")

plot(x = wavelength, y = flux, type = "l", main = "Quasar Lyman-alpha forest", 
     xlab = "Observed wavelength (Angstroms)", ylab = "Flux")
lines(wavelength.eval, tf.estimate, col = "orange", lwd = 2.5)
legend(x = "topleft", lwd = c(1,2), lty = 1, col = c("black","orange"), 
       legend = c("Noisy quasar Lyman-alpha forest", "Trend filtering estimate"))
}
\references{
\enumerate{
\item \href{https://academic.oup.com/mnras/article/492/3/4005/5704413}{
Politsch et al. (2020). Trend filtering – I. A modern statistical tool for 
time-domain astronomy and astronomical spectroscopy} \cr

\item \href{https://academic.oup.com/mnras/article/492/3/4019/5704414}{
Politsch et al. (2020). Trend filtering – II. Denoising astronomical signals 
with varying degrees of smoothness} \cr

\item \href{https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12_toc.pdf}{
Hastie et al. (2017). The Elements of Statistical Learning}
}
}
\seealso{
\code{\link{SURE.trendfilter}}, \code{\link{bootstrap.trendfilter}}
}
\author{
Collin A. Politsch, \email{collinpolitsch@gmail.com}
}
