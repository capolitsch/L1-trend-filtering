% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/cv.trendfilter.R
\name{cv.trendfilter}
\alias{cv.trendfilter}
\title{Optimize the trend filtering hyperparameter (by V-fold cross validation)}
\usage{
cv.trendfilter(
  x,
  y,
  weights = NULL,
  k = 2L,
  V = 5L,
  ngammas = 250L,
  gammas = NULL,
  gamma.choice = c("gamma.min", "gamma.1se"),
  validation.error.type = c("WMAE", "WMSE", "MAE", "MSE"),
  nx.eval = 1500L,
  x.eval = NULL,
  thinning = NULL,
  optimization.params = trendfilter.control.list(max_iter = 600L, obj_tol = 1e-10),
  mc.cores = detectCores()
)
}
\arguments{
\item{x}{The vector of observed values of the input variable (a.k.a. the 
predictor, covariate, explanatory variable, regressor, independent variable, 
control variable, etc.)}

\item{y}{The vector of observed values of the output variable (a.k.a. the
response, target, outcome, regressand, dependent variable, etc.).}

\item{weights}{A vector of weights for the observed outputs. These are 
defined as \code{weights = 1 / sigma^2}, where \code{sigma} is a vector of 
standard errors of the uncertainty in the output measurements. \code{weights} 
should either have length equal to 1 (corresponding to observations with a 
constant (scalar) variance of \code{sigma = 1/sqrt(weights)}) or length equal 
to \code{length(y)} (i.e. general heteroskedastic noise).}

\item{k}{The degree of the trend filtering estimator. Defaults to 
\code{k=2} (quadratic trend filtering). Must be one of \code{k = 0,1,2,3},
although \code{k=3} is discouraged due to algorithmic instability (and is
visually indistinguishable from \code{k=2} anyway).}

\item{V}{The number of folds the data are split into for the V-fold cross
validation. Defaults to \code{V=5} (recommended).}

\item{ngammas}{Integer. The number of trend filtering hyperparameter values 
to run the grid search over.}

\item{gammas}{Overrides \code{ngammas} if passed. A user-supplied vector of 
trend filtering hyperparameter values to run the grid search over. It is
advisable to let the vector be equally-spaced in log-space and provided in 
descending order. The function output will contain the sorted hyperparameter
vector regardless of the input ordering, and all related output objects 
(e.g. the \code{errors} vector) will correspond to the sorted ordering. 
Unless you know what you are doing, it is best to leave this \code{NULL}.
validation.}

\item{gamma.choice}{One of \code{c("gamma.min","gamma.1se")}. The choice
of hyperparameter that is used for optimized trend filtering estimate. 
\cr \cr
\code{gamma.min}: the hyperparameter value that minimizes the cross
validation error curve. \cr \cr
\code{gamma.1se}: the largest hyperparameter value with a cross
validation error within 1 standard error of the minimum cross validation 
error. This choice therefore favors simpler (i.e. smoother) trend filtering 
estimates. The motivation here is essentially Occam's razor: the two models
yield results that are quantitatively very close, so we favor the simpler
model.}

\item{validation.error.type}{Type of error to optimize during cross
validation. One of \code{c("WMAE","WMSE","MAE","MSE")}, i.e. mean-absolute 
deviations error, mean-squared error, and their weighted counterparts. 
If \code{weights = NULL}, then the weighted and 
unweighted counterparts are equivalent. In short, weighting helps combat
heteroskedasticity and absolute error decreases sensitivity to outliers.
Defaults to \code{"WMAE"}.}

\item{nx.eval}{The length of the equally-spaced input grid to evaluate the 
evaluate the optimized trend filtering estimate on.}

\item{x.eval}{Overrides \code{nx.eval} if passed. A user-supplied grid of 
inputs to evaluate the optimized trend filtering estimate on.}

\item{thinning}{logical. If \code{TRUE}, then the data are preprocessed so 
that a smaller, better conditioned data set is used for fitting. When left
\code{NULL}, the default, the optimization will automatically detect whether 
thinning should be applied (i.e., cases in which the numerical fitting 
algorithm will struggle to converge). This preprocessing procedure is 
controlled by the \code{x_tol} argument of 
\code{\link[glmgen]{trendfilter.control.list}}.}

\item{optimization.params}{a named list of parameters produced by the
\pkg{glmgen} function \code{\link[glmgen]{trendfilter.control.list}} that
contains all parameter choices (user-supplied or defaults) to be passed to 
the trend filtering ADMM algorithm
(\href{http://www.stat.cmu.edu/~ryantibs/papers/fasttf.pdf}{Ramdas and
Tibshirani 2016}). See the linked function documentation for full details. 
No technical understanding of the ADMM algorithm is needed and the default
parameter choices will almost always suffice. However, the following three 
parameters may require some adjustments to ensure that your trend filtering
estimate has sufficiently converged:
\enumerate{ 
\item{\code{max_iter}}: Maximum iterations allowed for the trend filtering 
convex optimization. Defaults to \code{max_iter = 600L}. Increase this if 
the trend filtering estimate does not appear to have fully converged to a 
reasonable estimate of the signal.
\item{\code{obj_tol}}: The tolerance used in the convex optimization stopping 
criterion; when the relative change in the objective function is less than 
this value, the algorithm terminates. Decrease this if the trend filtering 
estimate does not appear to have fully converged to a reasonable estimate of 
the signal.
\item{x_tol}: defines uniqueness or sameness of \code{x}'s. If we make bins 
of size \code{x_tol} and find at least two \code{x}'s which fall into the 
same bin, then we thin the data.
}}

\item{mc.cores}{Multi-core computing (for speedups): The number of cores to
utilize. Defaults to the number of cores detected.}
}
\value{
An object of class 'cv.trendfilter'. This is a list with the 
following elements:
\item{x.eval}{The grid of inputs the optimized trend filtering estimate was 
evaluated on.}
\item{tf.estimate}{The optimized trend filtering estimate of the signal, 
evaluated on \code{x.eval}.}
\item{validation.method}{\code{paste0(V,"-fold CV")}}
\item{V}{The number of folds the data are split into for the V-fold cross
validation.}
\item{validation.error.type}{Type of error that validation was performed on. 
One of \code{c("WMAE","WMSE","MAE","MSE")}.}
\item{gammas}{Vector of hyperparameter values tested during validation. This
vector will always be returned in descending order, regardless of the 
ordering provided by the user. The indices \code{i.min} and \code{i.1se}
correspond to this descending ordering.}
\item{gamma.min}{Hyperparameter value that minimizes the SURE error curve.}
\item{gamma.1se}{The largest hyperparameter value that is still within one
standard error of the minimum hyperparameter's cross validation error.}
\item{gamma.choice}{One of \code{c("gamma.min","gamma.1se")}. The choice
of hyperparameter that is used for optimized trend filtering estimate.}
\item{edfs}{Vector of effective degrees of freedom for trend filtering
estimators fit during validation.}
\item{edf.min}{The effective degrees of freedom of the optimally-tuned trend 
filtering estimator.}
\item{edf.1se}{The effective degrees of freedom of the 1-stand-error rule
trend filtering estimator.}
\item{i.min}{The index of \code{gammas} that minimizes the cross validation 
error.}
\item{i.1se}{The index of \code{gammas} that gives the largest hyperparameter
value that has a cross validation error within 1 standard error of the 
minimum of the cross validation error curves.}
\item{errors}{Vector of cross validation errors for the given hyperparameter 
values.}
\item{se.errors}{The standard errors of the cross validation errors.
These are particularly useful for implementing the ``1-standard-error rule''. 
The 1-SE rule favors a smoother trend filtering estimate by, instead of 
using the hyperparameter that minimizes the CV error, instead uses the 
largest hyperparameter that has a CV error within 1 standard error of the
smallest CV error.}
\item{x}{The vector of the observed inputs.}
\item{y}{The vector of the observed outputs.}
\item{weights}{A vector of weights for the observed outputs. These are
defined as \code{weights = 1/sigma^2}, where \code{sigma} is a vector of 
standard errors of the uncertainty in the measured outputs.}
\item{fitted.values}{The trend filtering estimate of the signal, evaluated at
the observed inputs \code{x}.}
\item{residuals}{\code{residuals = y - fitted.values}.}
\item{k}{The degree of the trend filtering estimator.}
\item{thinning}{logical. If \code{TRUE}, then the data are preprocessed so 
that a smaller, better conditioned data set is used for fitting.}
\item{optimization.params}{a list of parameters that control the trend
filtering convex optimization.}
\item{n.iter}{Vector of the number of iterations needed for the ADMM
algorithm to converge within the given tolerance, for each hyperparameter
value. If many of these are exactly equal to \code{max_iter}, then their
solutions have not converged with the tolerance specified by \code{obj_tol}.
In which case, it is often prudent to increase \code{max_iter}.}
\item{x.scale, y.scale, data.scaled}{for internal use.}
}
\description{
\loadmathjax{} \code{cv.trendfilter} performs V-fold cross 
validation to estimate the random-input squared error of a trend filtering 
estimator on a grid of values for the hyperparameter \code{gamma}, and 
returns the full error curve and the optimized trend filtering estimate 
within a larger list with useful ancillary information.
}
\details{
This will be a very detailed description... \cr \cr
\mjeqn{WMAE(\gamma) = \frac{1}{n}\sum_{i=1}^{n} |Y_i - \widehat{f}(x_i; \gamma)|\frac{\sqrt{w_i}}{\sum_j\sqrt{w_j}}}{ascii} \cr 
\mjeqn{WMSE(\gamma) = \frac{1}{n}\sum_{i=1}^{n} |Y_i - \widehat{f}(x_i; \gamma)|^2\frac{w_i}{\sum_jw_j}}{ascii} \cr 
\mjeqn{MAE(\gamma) = \frac{1}{n}\sum_{i=1}^{n} |Y_i - \widehat{f}(x_i; \gamma)|}{ascii} \cr 
\mjeqn{MSE(\gamma) = \frac{1}{n}\sum_{i=1}^{n} |Y_i - \widehat{f}(x_i; \gamma)|^2}{ascii} \cr \cr 
where \mjeqn{\widehat{f}(x_i; \gamma)}{ascii} is the trend filtering 
estimate with hyperparameter \eqn{\gamma}, evaluated at 
\mjeqn{x_i}{ascii}.
}
\examples{
#######################################################################
###  Phase-folded light curve of an eclipsing binary star system   ####
#######################################################################

# A binary star system is a pair of closely-separated stars that move
# in an orbit around a common center of mass. When a binary star system 
# is oriented in such a way that the stars eclipse one another from our 
# vantage point on Earth, we call it an 'eclipsing binary (EB) star 
# system'. From our perspective, the total brightness of an EB dips 
# periodically over time due to the stars eclipsing one another. And 
# the shape of the brightness curve is consistent within each period
# of the orbit. In order to learn about the physics of these EBs,
# astronomers 'phase-fold' the brightness curve so that all the orbital 
# periods are stacked on top of one another in a plot of the EB's phase 
# vs. its apparent brightness, and then find a 'best-fitting' model
# for the phase-folded curve. Here, we use trend filtering to fit an
# optimal phase-folded model for an EB.

data(eclipsing_binary)

# head(data)
#
# |      phase|      flux|  std.err|
# |----------:|---------:|--------:|
# | -0.4986308| 0.9384845| 0.010160|
# | -0.4978067| 0.9295757| 0.010162|
# | -0.4957892| 0.9438493| 0.010162|

# This specific choice of values did not come a priori
gamma.grid <- exp( seq(7, 16, length = 150) )

cv.out <- cv.trendfilter(x = data$phase, 
                         y = data$flux, 
                         weights = 1 / data$std.err ^ 2,
                         gammas = gamma.grid,
                         validation.error.type = "MAE",
                         thinning = TRUE, 
                         optimization.params = trendfilter.control.list(max_iter = 5e3,
                                                                        obj_tol = 1e-6)
                         )

# Plot the results

par(mfrow = c(2,1), mar = c(5,4,2.5,1) + 0.1)
plot(log(cv.out$gammas), cv.out$errors, main = "CV error curve", 
     xlab = "log(gamma)", ylab = "CV error")
segments(x0 = log(cv.out$gammas), x1 = log(cv.out$gammas), 
         y0 = cv.out$errors - cv.out$se.errors, 
         y1 = cv.out$errors + cv.out$se.errors)
abline(v = log(cv.out$gamma.min), lty = 2, col = "blue3")
text(x = log(cv.out$gamma.min), y = par("usr")[4], 
     labels = "optimal gamma", pos = 1, col = "blue3")
plot(data$phase, data$flux, cex = 0.15, xlab = "Phase", ylab = "Flux",
     main = "Eclipsing binary phase-folded light curve")
segments(x0 = data$phase, x1 = data$phase, 
         y0 = data$flux - data$std.err, y1 = data$flux + data$std.err, 
         lwd = 0.25)
lines(cv.out$x.eval, cv.out$tf.estimate, col = "orange", lwd = 2.5)
}
\references{
\strong{Cross validation}
\enumerate{
\item Hastie, Tibshirani, and Friedman (2009). The Elements of Statistical 
Learning: Data Mining, Inference, and Prediction. 2nd edition. Springer 
Series in Statistics. 
\href{https://web.stanford.edu/~hastie/ElemStatLearn/printings/ESLII_print12_toc.pdf}{
[Online print #12]}. (See Sections 7.10 and 7.12) \cr
\item James, Witten, Hastie, and Tibshirani (2013). An Introduction to 
Statistical Learning : with Applications in R. Springer.
\href{https://www.statlearning.com/}{[Most recent online print]} (See 
Section 5.1). \emph{Less technical than the above reference.}\cr
\item Tibshirani (2013). Model selection and validation 2: Model
assessment, more cross-validation. \emph{36-462: Data Mining course notes} 
(Carnegie Mellon).
\href{https://www.stat.cmu.edu/~ryantibs/datamining/lectures/19-val2.pdf}{
[Link]}
}
\strong{Trend filtering optimization algorithm}
\enumerate{
\item{Ramdas and Tibshirani (2016). Fast and Flexible ADMM Algorithms 
for Trend Filtering. \emph{Journal of Computational and Graphical 
Statistics}, 25(3), p. 839-858.
\href{https://amstat.tandfonline.com/doi/abs/10.1080/10618600.2015.1054033#.XfJpNpNKju0}{
[Link]}} \cr
\item{Arnold, Sadhanala, and Tibshirani (2014). Fast algorithms for 
generalized lasso problems. R package \emph{glmgen}. Version 0.0.3. 
\href{https://github.com/glmgen/glmgen}{[Link]}} \cr
(Software implementation of Ramdas and Tibshirani algorithm) \cr
}
}
\seealso{
\code{\link{SURE.trendfilter}}, \code{\link{bootstrap.trendfilter}}
}
\author{
Collin A. Politsch, \email{collinpolitsch@gmail.com}
}
